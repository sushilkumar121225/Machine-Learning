# ğŸ“‰ Dimensionality Reduction using PCA on Handwritten Digits (MNIST)

---

## ğŸ“Œ Introduction
In Machine Learning, datasets often contain **many features**, which makes computation slow and visualization difficult.  
**Dimensionality Reduction** helps reduce the number of features while keeping important information.

In this practical, we use **Principal Component Analysis (PCA)** to reduce the dimensionality of the **MNIST Handwritten Digits dataset** and visualize the results.

---

## ğŸ¯ Objective
- To understand **PCA (Principal Component Analysis)**
- To reduce high-dimensional image data (784 features) into fewer components
- To visualize handwritten digits in **2D and 3D**
- To observe how PCA preserves important information

---

## ğŸ“‚ Dataset Information
- **Dataset Name:** MNIST Handwritten Digits
- **Total Samples:** 70,000
- **Image Size:** 28 Ã— 28 pixels
- **Features:** 784 pixel values per image
- **Classes:** Digits from 0 to 9

ğŸ“Œ The dataset is converted into a **CSV file (`mnist_dataset.csv`)** during execution in Google Colab.

---

## ğŸ› ï¸ Technologies & Tools Used
- Python  
- Google Colab  
- NumPy  
- Pandas  
- Matplotlib  
- Scikit-Learn  

---

## ğŸ§  What is PCA? (Easy Explanation)
**Principal Component Analysis (PCA)** is a technique used to:
- Reduce the number of features
- Remove unnecessary information (noise)
- Keep the most important patterns in the data

ğŸ‘‰ PCA works by finding **new axes (principal components)** that capture **maximum variance** in the data.

---

## âš™ï¸ Methodology (Step-by-Step)

### 1ï¸âƒ£ Load MNIST Dataset
- MNIST dataset is loaded using `fetch_openml`
- Pixel values and labels are separated

---

### 2ï¸âƒ£ Convert Dataset to CSV
- The MNIST data is saved as `mnist_dataset.csv`
- This allows reuse of the dataset for other ML tasks

---

### 3ï¸âƒ£ Data Standardization
- Features are standardized using `StandardScaler`
- This ensures PCA performs correctly

---

### 4ï¸âƒ£ Apply PCA
- PCA is applied with **50 components**
- Dimensionality is reduced from **784 â†’ 50**

---

### 5ï¸âƒ£ Explained Variance Analysis
- A graph shows how much variance is retained
- Helps decide the optimal number of components

---

### 6ï¸âƒ£ 2D PCA Visualization
- Data is projected into **2 dimensions**
- Digits form visible clusters

---

### 7ï¸âƒ£ 3D PCA Visualization
- Data is projected into **3 dimensions**
- Better separation of digit classes

---

### 8ï¸âƒ£ Image Reconstruction
- Images are reconstructed from reduced components
- Comparison shows minimal quality loss

---

## ğŸ“Š Results & Observations
- PCA successfully reduced data size
- More than **90% variance retained**
- Digits remain recognizable after reconstruction
- Visualization becomes easier and faster

---

## ğŸ“ˆ Graphs & Visual Output
âœ” Cumulative Explained Variance Plot  
âœ” 2D PCA Scatter Plot  
âœ” 3D PCA Scatter Plot  
âœ” Original vs Reconstructed Images  

---

## âœ… Advantages of PCA
- Reduces computational cost
- Removes noise
- Improves visualization
- Helps in faster model training

---

## ğŸ“Œ Applications
- Image compression
- Face recognition
- Data visualization
- Noise reduction
- Preprocessing in ML models

---

## ğŸ Conclusion
This practical demonstrates how **PCA effectively reduces high-dimensional data** while preserving essential information.  
It proves that dimensionality reduction is crucial for handling large datasets like MNIST.

---

## ğŸ“ Files Included
- `mnist_dataset.csv` â€“ Dataset in CSV format  this basically download after run the program
- `pca.ipynb` â€“ Google Colab notebook
- `output`
- `README.md` â€“ Project documentation  

---

-----------------------------------------------------------------------------------------------------------
                                                Follow Me
-----------------------------------------------------------------------------------------------------------
ğŸ¤ Contributing
Feel free to fork the repository, improve the project, and submit a pull request.

ğŸ“Š Connect with me:
If you want to see more ML projects, tutorials, and updates, follow me on:

â€¢â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â€¢â€¢â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â€¢
        ğŸ‘©â€ğŸ’» Author
â€¢â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â€¢â€¢â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â€¢
# Sushil Kumar
ğŸ“§ [ Email: sushilkumarnk25102@gmail.com ]
ğŸ™ [ Git Hub: https://github.com/sushilkumar121225 ]
ğŸ”— [ LinkedIn: https://www.linkedin.com/in/sushil-kumar-471614289/ ]
ğŸ§© B.tech Computer Engineering (Full stack developer)

ğŸ™Œ Thank You for Visiting This Repository!
Happy Learning and Keep Exploring 


## â­ If you like this project
Give a â­ on GitHub and feel free to fork!
